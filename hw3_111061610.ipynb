{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "894384f9",
      "metadata": {
        "id": "894384f9"
      },
      "source": [
        "# Numerical Optimization (CS215300) Assignment 3\n",
        "## Introduction\n",
        "In this assignment, we expect you to be able to solve constrained optimization problem by Scipy library. We want you to apply two algorithms on the following problem as a benchmark, survey the methods used in these libraries, and analyze the behavior of these algorithms.\n",
        "The library document link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n",
        "\n",
        "## Task\n",
        "1. (20%) Solve the following problrem by using **trust-constr** method:\n",
        "$$\\begin{array}{lll}\n",
        "        \\min_{x_1,x_2} & f(x_1,x_2)=-x_1-x_2 \\\\\n",
        "        \\mbox{s.t. } & -2x_1^4 + 8x_1^3 -8x_1^2 + x_2 - 2 \\le 0  \\\\\n",
        "         & -4x_1^4 + 32x_1^3 - 88x_1^2 + 96x_1 + x_2 -36 \\le 0   \\\\\n",
        "         & 0 \\le x_1 \\le 3 \\\\\n",
        "         & 0 \\le x_2 \\le 4 \\\\\n",
        "\\end{array}$$\n",
        "2. (20%) Use **COBYLA** method to solve the same problem.\n",
        "3. (15%) For the above two algorithms, please include the calculation process in markdown style before your code cells.\n",
        "4. (5%) Provide the Jacobian and Hessian function in matrix form in markdown style.\n",
        "5. (40%) In your report, please read the paper cited in the libraries, which gives the details of the algorithms. Write an introduction of the algorithms, and compare their behaviors in this benchmark. You are not necessarily to read the original paper, other resourses (ex. slides from other schools or surveys) are also acceptable. Please include the link or paper name in your reference if you referred to other resources.\n",
        "6. Rename this notebook file by adding your student ID and upload it to eeclass platform. (ex. hw3_110xxxxxx.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c364c0",
      "metadata": {
        "id": "76c364c0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea454f92",
      "metadata": {
        "id": "ea454f92"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import Bounds\n",
        "from scipy.optimize import NonlinearConstraint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f49385",
      "metadata": {
        "id": "21f49385"
      },
      "source": [
        "### Define objective function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "908e2508",
      "metadata": {
        "id": "908e2508"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    # TODO\n",
        "    return -x[0]-x[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a248684d",
      "metadata": {
        "id": "a248684d"
      },
      "source": [
        "### Define constraint functions and derivatives\n",
        "Note: Please do not use sparse matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193a8cdb",
      "metadata": {
        "id": "193a8cdb"
      },
      "outputs": [],
      "source": [
        "# TODO: derive and define the functions\n",
        "def cons_f(x):\n",
        "    # TODO\n",
        "    return [-2 * x[0] ** 4 + 8 * x[0] ** 3 - 8 * x[0] ** 2 + x[1] - 2, -4 * x[0] ** 4 + 32 * x[0] ** 3 - 88 * x[0] ** 2 + 96 * x[0] + x[1] - 36]\n",
        "    \n",
        "def cons_Jacobian(x):\n",
        "    # TODO\n",
        "    return np.array([[-8 * x[0] ** 3 + 24 * x[0] ** 2 - 16 * x[0], 1], [-16 * x[0] ** 3 + 96 * x[0] ** 2 - 176 * x[0] + 96, 1]]) #[(df/dx1,df/dx2)]\n",
        "\n",
        "def cons_Hessian(x,v):\n",
        "    # TODO\n",
        "    return v[0] * np.array([[-24 * x[0] ** 2 + 48 * x[0] - 16, 0], [0, 0]]) + v[1] * np.array([[-48 * x[0] ** 2 + 192 * x[0] - 176, 0], [0, 0]]) # v = Lagrange multipliers.\n",
        "\n",
        "# TODO: Insert the functions above into a NonlinearConstraint obeject\n",
        "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 0, jac=cons_Jacobian, hess=cons_Hessian)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Jacobian and Hessian function in matrix form in markdown style**\n",
        "\n",
        "$Jacobain$ = \n",
        "$\\begin{bmatrix}\n",
        "\\frac {\\partial f_1(\\vec{x})}{\\partial x_1} & \\frac {\\partial f_1(\\vec{x})}{\\partial x_2}\\\\ \n",
        "\\frac {\\partial f_2(\\vec{x})}{\\partial x_1} & \\frac {\\partial f_2(\\vec{x})}{\\partial x_2}\\end{bmatrix}=\n",
        "\\begin{bmatrix} \n",
        "-8x_1^3+24x_1^2 -16x_1 & 1 \\\\ \n",
        "-16x_1^3+96x_1^2-176x_1+96 & 1\n",
        "\\end{bmatrix}$ \n",
        "\n",
        "$Hessian = \n",
        "v_1$\n",
        "$\\begin{bmatrix}\n",
        "\\frac {\\partial^2 f_1(\\vec{x})}{\\partial x_1^2} & \\frac {\\partial^2 f_1(\\vec{x})}{\\partial x_1\\partial x_2} \\\\ \n",
        "\\frac {\\partial^2 f_1(\\vec{x})}{\\partial x_1\\partial x_2} & \\frac {\\partial^2 f_1(\\vec{x})}{\\partial x_2^2}\n",
        "\\end{bmatrix}+ v_2\\begin{bmatrix}\\frac {\\partial^2 f_2(\\vec{x})}{\\partial x_1^2} & \\frac {\\partial^2 f_2(\\vec{x})}{\\partial x_1\\partial x_2} \\\\ \n",
        "\\frac {\\partial^2 f_2(\\vec{x})}{\\partial x_1\\partial x_2} & \\frac {\\partial^2 f_2(\\vec{x})}{\\partial x_2^2}\n",
        "\\end{bmatrix}$=\n",
        "\n",
        "$v_1\\begin{bmatrix} \n",
        "-24x_1^2+48x_1 -16 & 0 \\\\ \n",
        "0 & 0 \n",
        "\\end{bmatrix}\n",
        "+v_2\n",
        "\\begin{bmatrix}  \n",
        "-48x_1^2+192x_1-176 & 0 \\\\ \n",
        "0 & 0 \n",
        "\\end{bmatrix}$\n",
        "\n",
        "where $v_1$ and $v_2$ are Lagrange multipliers."
      ],
      "metadata": {
        "id": "o3FIKP0bdjAF"
      },
      "id": "o3FIKP0bdjAF"
    },
    {
      "cell_type": "markdown",
      "id": "057a3b50",
      "metadata": {
        "id": "057a3b50"
      },
      "source": [
        "### Define the bounds "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0b7092",
      "metadata": {
        "id": "2c0b7092"
      },
      "outputs": [],
      "source": [
        "# TODO: define the bounds\n",
        "bounds = Bounds([0,3], [0,4])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03b1a98",
      "metadata": {
        "id": "a03b1a98"
      },
      "source": [
        "### Call the minimize library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **trust-constr method calculation process**\n",
        "\n",
        "1.  Guess an initial trust region $∆_0$ and an initial $x_0$.\n",
        "2. For k = 0, 1, 2, . . . until convergence\n",
        "\n",
        "  a.Build a model $m_k$ of f at $x_k$\n",
        "\n",
        "  b.Solve the constrained minimization problem: $\\underset{p}{min}$ $m_k$ $(\\vec{p})$ s.t. $\\|p\\|$ ≤ $∆_k$ \n",
        "\n",
        "  c.Evaluate the trust region $∆_k$ . If not satisfied, update $∆_k$ and goto (2.b)\n",
        "\n",
        "  d.Set $x_{k+1}$ = $x_k$ + $p_k$ where $p_k$ is the solution of the model problem.\n"
      ],
      "metadata": {
        "id": "6dewrjDdC0Jw"
      },
      "id": "6dewrjDdC0Jw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9439bc43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9439bc43",
        "outputId": "7e8e8c95-dd8a-487d-92d3-a515a5250ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
            "  warn('delta_grad == 0.0. Check if the approximated '\n",
            "/usr/local/lib/python3.8/dist-packages/scipy/optimize/_trustregion_constr/projections.py:181: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
            "  warn('Singular Jacobian matrix. Using SVD decomposition to ' +\n"
          ]
        }
      ],
      "source": [
        "# TODO: define initial point\n",
        "from scipy.optimize import minimize\n",
        "import scipy.optimize as scopt\n",
        "\n",
        "x0 = np.array([1,1])\n",
        "x1 = np.array([0,0])\n",
        "res = minimize(f, x0, method='trust-constr',  jac = 'BFGS', hess = scopt.BFGS(), constraints=[nonlinear_constraint], bounds=bounds,)\n",
        "res_1 = minimize(f, x1, method='trust-constr',  jac = 'BFGS', hess = scopt.BFGS(), constraints=[nonlinear_constraint], bounds=bounds,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96a8225",
      "metadata": {
        "id": "e96a8225"
      },
      "source": [
        "### Print out the result you get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b38ec278",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b38ec278",
        "outputId": "00321658-1ec5-490f-85ed-06d017999992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " barrier_parameter: 2.048000000000001e-09\n",
            " barrier_tolerance: 2.048000000000001e-09\n",
            "          cg_niter: 407\n",
            "      cg_stop_cond: 2\n",
            "            constr: [array([ 0.12392828, -7.75860644]), array([0.37810521, 2.87607172])]\n",
            "       constr_nfev: [586, 0]\n",
            "       constr_nhev: [111, 0]\n",
            "       constr_njev: [110, 0]\n",
            "    constr_penalty: 4294465.180582135\n",
            "  constr_violation: 0.37810520891180693\n",
            "    execution_time: 0.6377410888671875\n",
            "               fun: -3.2541769310260924\n",
            "              grad: array([-1., -1.])\n",
            "               jac: [array([[-3.05100027,  1.        ],\n",
            "       [42.31309974,  1.        ]]), array([[1., 0.],\n",
            "       [0., 1.]])]\n",
            "   lagrangian_grad: array([5.55111512e-16, 0.00000000e+00])\n",
            "           message: '`xtol` termination condition is satisfied.'\n",
            "            method: 'tr_interior_point'\n",
            "              nfev: 1758\n",
            "              nhev: 0\n",
            "               nit: 419\n",
            "             niter: 419\n",
            "              njev: 586\n",
            "        optimality: 5.551115123125783e-16\n",
            "            status: 2\n",
            "           success: True\n",
            "         tr_radius: 7.168345846848407e-09\n",
            "                 v: [array([-1.81366372e-01,  2.63964926e-10]), array([0.44665114, 1.18136637])]\n",
            "                 x: array([0.37810521, 2.87607172])\n",
            "[0.37810521 2.87607172]\n"
          ]
        }
      ],
      "source": [
        "print(res)\n",
        "print(res.x) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res_1)\n",
        "print(res_1.x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxFj-QCMqE9F",
        "outputId": "1f69fdc6-0358-45dd-859f-21a0bef45577"
      },
      "id": "lxFj-QCMqE9F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " barrier_parameter: 0.1\n",
            " barrier_tolerance: 0.1\n",
            "          cg_niter: 115\n",
            "      cg_stop_cond: 4\n",
            "            constr: [array([  0.31604725, -36.98886681]), array([-0.03348254,  2.3253187 ])]\n",
            "       constr_nfev: [995, 0]\n",
            "       constr_nhev: [987, 0]\n",
            "       constr_njev: [986, 0]\n",
            "    constr_penalty: 80.96885126678468\n",
            "  constr_violation: 0.6746812968873561\n",
            "    execution_time: 3.436415433883667\n",
            "               fun: -2.291836159294053\n",
            "              grad: array([-1., -1.])\n",
            "               jac: [array([[  0.56292693,   1.        ],\n",
            "       [102.00115205,   1.        ]]), array([[1., 0.],\n",
            "       [0., 1.]])]\n",
            "   lagrangian_grad: array([0.00097656, 0.        ])\n",
            "           message: 'The maximum number of function evaluations is exceeded.'\n",
            "            method: 'tr_interior_point'\n",
            "              nfev: 2985\n",
            "              nhev: 0\n",
            "               nit: 1000\n",
            "             niter: 1000\n",
            "              njev: 995\n",
            "        optimality: 0.0009765625\n",
            "            status: 0\n",
            "           success: False\n",
            "         tr_radius: 9.601369453642803e-05\n",
            "                 v: [array([7.61024005e+12, 2.70811747e-03]), array([-4.28400909e+12, -7.61024005e+12])]\n",
            "                 x: array([-0.03348254,  2.3253187 ])\n",
            "[-0.03348254  2.3253187 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.array([0,1])\n",
        "res = minimize(f, x0, method='trust-constr',  jac = 'BFGS', hess = scopt.BFGS(), constraints=[nonlinear_constraint], bounds=bounds,)\n",
        "print(res)\n",
        "print(res.x) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCK7ZUEfvguH",
        "outputId": "ffeeacd2-a1e2-4dde-f80e-ab1e98dd05fa"
      },
      "id": "MCK7ZUEfvguH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
            "  warn('delta_grad == 0.0. Check if the approximated '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " barrier_parameter: 0.1\n",
            " barrier_tolerance: 0.1\n",
            "          cg_niter: 115\n",
            "      cg_stop_cond: 1\n",
            "            constr: [array([  0.19346202, -37.77155383]), array([-0.03995586,  2.20674919])]\n",
            "       constr_nfev: [999, 0]\n",
            "       constr_nhev: [988, 0]\n",
            "       constr_njev: [987, 0]\n",
            "    constr_penalty: 136.36337464447533\n",
            "  constr_violation: 0.7932508083945327\n",
            "    execution_time: 2.247462272644043\n",
            "               fun: -2.166793335346139\n",
            "              grad: array([-1., -1.])\n",
            "               jac: [array([[  0.6781193 ,   1.        ],\n",
            "       [103.18651248,   1.        ]]), array([[1., 0.],\n",
            "       [0., 1.]])]\n",
            "   lagrangian_grad: array([0.        , 0.00195312])\n",
            "           message: 'The maximum number of function evaluations is exceeded.'\n",
            "            method: 'tr_interior_point'\n",
            "              nfev: 2997\n",
            "              nhev: 0\n",
            "               nit: 1000\n",
            "             niter: 1000\n",
            "              njev: 999\n",
            "        optimality: 0.001953125\n",
            "            status: 0\n",
            "           success: False\n",
            "         tr_radius: 0.00017119331002079797\n",
            "                 v: [array([1.08357221e+13, 2.65401852e-03]), array([-7.34791224e+12, -1.08357221e+13])]\n",
            "                 x: array([-0.03995586,  2.20674919])\n",
            "[-0.03995586  2.20674919]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.array([1,0])\n",
        "res = minimize(f, x0, method='trust-constr',  jac = 'BFGS', hess = scopt.BFGS(), constraints=[nonlinear_constraint], bounds=bounds,)\n",
        "print(res)\n",
        "print(res.x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EXO4Ahqvr03",
        "outputId": "e82a565c-f0ed-4e62-f35f-3a97e43a9361"
      },
      "id": "1EXO4Ahqvr03",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/optimize/_trustregion_constr/projections.py:181: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
            "  warn('Singular Jacobian matrix. Using SVD decomposition to ' +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " barrier_parameter: 2.048000000000001e-09\n",
            " barrier_tolerance: 2.048000000000001e-09\n",
            "          cg_niter: 448\n",
            "      cg_stop_cond: 2\n",
            "            constr: [array([ 0.12392828, -7.75860644]), array([0.37810521, 2.87607172])]\n",
            "       constr_nfev: [730, 0]\n",
            "       constr_nhev: [126, 0]\n",
            "       constr_njev: [125, 0]\n",
            "    constr_penalty: 4323611.87606519\n",
            "  constr_violation: 0.3781052089118065\n",
            "    execution_time: 0.6534969806671143\n",
            "               fun: -3.2541769310261195\n",
            "              grad: array([-1., -1.])\n",
            "               jac: [array([[-3.05100027,  1.        ],\n",
            "       [42.31309974,  1.        ]]), array([[1., 0.],\n",
            "       [0., 1.]])]\n",
            "   lagrangian_grad: array([1.33226763e-15, 2.22044605e-16])\n",
            "           message: '`xtol` termination condition is satisfied.'\n",
            "            method: 'tr_interior_point'\n",
            "              nfev: 2190\n",
            "              nhev: 0\n",
            "               nit: 460\n",
            "             niter: 460\n",
            "              njev: 730\n",
            "        optimality: 1.3322676295501878e-15\n",
            "            status: 2\n",
            "           success: True\n",
            "         tr_radius: 7.171014227603731e-09\n",
            "                 v: [array([-1.81366372e-01,  2.63964926e-10]), array([0.44665114, 1.18136637])]\n",
            "                 x: array([0.37810521, 2.87607172])\n",
            "[0.37810521 2.87607172]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COBYLA method calculation process**\n",
        "\n",
        "This task requires the vertices \n",
        "{$x^{(j)}$ : j = 0,1, ... , n} of a nondegenerate simplex, a positive trust region radius $\\rho$, \n",
        "and the current value of the parameter $μ$ of the merit function.The vertices \n",
        "have already been ordered so that $x^{(O)}$ is optimal, which means that the inequalities  \n",
        "\n",
        "$\\Rightarrow \\Phi(x^{(0)}) \\leq \\Phi(x^{j}),\\quad j=0,1,2,...,n, \\quad \\quad (1)$\n",
        "\n",
        "are satisfied. Then the trust region condition on the new vector of variables, $x^{(*)}$ \n",
        "say, is the bound\n",
        "\n",
        "$\\Rightarrow \\| x^{(*)}-x^{(0)}\\|_2 \\leq \\rho \\quad \\quad (2)$\n",
        "\n",
        "If possible, we let $x^{(*)}$ minimize the linear approximation $\\hat{F}(x^{(*)})$ to the objective \n",
        "function subject to the inequality (2) and to the linear constraints of the problem\n",
        "\n",
        "$\\Rightarrow \\hat{c_i}(x^{(*)}) \\ge 0, \\quad i=1,2,...,m, \\quad \\quad (3)$\n",
        "\n",
        "picking the $x^{(*)}$ that gives the least value of $\\|x^{(*)}-x^{(0)}\\|_2$ if \n",
        "these conditions admit more than one $x^{(*)}$. Alternatively, it can happen that the \n",
        "inequalities (2) and (3) are contradictory. Then we define $x^{(*)}$ by minimizing the \n",
        "greatest of the constraint violations $\\{-\\hat{c_i}(x^{(*)}) : i = 1,2, ... , m\\}$ subject to the trust \n",
        "region bound. Further, any remaining freedom in $x^{(*)}$ is used to minimize $\\hat{F}(x^{(*)})$ \n",
        "and, if some freedom still remains, then we remove the ambiguity by again making \n",
        "$\\|x^{(*)}-x^{(0)}\\|_2$ as small as possible. The calculation of $x^{(*)}$ has been implemented \n",
        "by imagining that $\\rho$ is increased continuously from zero to the current value. The \n",
        "sequence of values of $x^{(*)}$ that would occur for this range of $\\rho$ is a continuous trajec\u0002tory that is composed of straight line pieces. It is convenient to follow the trajectory \n",
        "from $x^{(O)}$ to the required $x^{(*)}$ by identifying and updating the active sets of linear \n",
        "constraints that define the linear pieces. \n",
        "\n",
        "Next we describe the adjustment of $\\mu$, because it depends on the $x^{(*)}$ that has \n",
        "just been specified. We set $\\mu$ = 0 initially, but in this case, when choosing the \n",
        "optimal vertex, it is assumed that $\\mu$ is a tiny positive number whose value need not \n",
        "be specified. Later we take the view that it is unreasonable to expect the reduction \n",
        "$\\Phi(x^{(*)}) \\leq \\Phi(x^{(0)})$ in the merit function if the value of $\\mu$ does not provide the \n",
        "condition $\\Phi(x^{(*)}) \\leq \\Phi(x^{(0)})$, where $\\Phi$ is the approximation\n",
        "\n",
        "$\\Rightarrow \\Phi(x)=\\hat{F}(x)+\\mu [ max\\{-\\hat{c_i}(x): i=1,2,,...,m \\} ]_+, \\quad \\quad x \\in R^{n},$\n"
      ],
      "metadata": {
        "id": "BT1RG7HOtX0l"
      },
      "id": "BT1RG7HOtX0l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Set $\\rho$=$\\rho_{beg},\\mu=0$ and $Branch=(*)$. Form the initial simplex.\n",
        "\n",
        "2. Ensure that $x^{(0)}$ is the optimal vertex and that FLAG=ON if the simplex is acceptable. \n",
        "\n",
        "3. 判斷$Branch=(*) \\quad or \\quad FLAG=ON? $\n",
        "\n",
        " $Yes : Generate$ $x^{(*)}$\n",
        "\n",
        " $No : Calculate \\quad x^{(\\Delta)}, F(x^{(\\Delta)})$ and $\\{c_i(x^{(\\Delta)}): i=1,2, ... ,m\\}.$ Make $x^{(\\Delta)}$ a vertex of the simplex. Set $ Branch=(*).$\n",
        "\n",
        "4. If Yes,then 判斷 $\\| x^{(*)}-x^{(0)}\\|_2 \\leq \\frac{1}{2}\\rho ?$\n",
        "\n",
        "5. 判斷 $\\frac{\\Phi(x^{(0)})-\\Phi(x^{(*)})}{\\hat{\\Phi}(x^{(0)})-\\hat{\\Phi}(x^{(*)})} \\leq 0.1$\n",
        "\n",
        "6. 確認 $FLAG=ON?$ 如果沒有，$Set \\quad Branch=(\\Delta)$\n",
        "\n",
        "7. 如果 $FLAG=ON?\\quad is \\quad Yes$， 判斷 $\\rho \\leq \\rho_{end} ?$ end"
      ],
      "metadata": {
        "id": "OT8Ur_wvz0mJ"
      },
      "id": "OT8Ur_wvz0mJ"
    },
    {
      "cell_type": "markdown",
      "id": "62bd5cee",
      "metadata": {
        "id": "62bd5cee"
      },
      "source": [
        "### Apply COBYLA method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b7e7f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82b7e7f0",
        "outputId": "30422955-e89d-4bd3-f1c3-028c56d939a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     fun: -5.508012518922257\n",
            "   maxcv: 3.6417964892621058e-06\n",
            " message: 'Optimization terminated successfully.'\n",
            "    nfev: 25\n",
            "  status: 1\n",
            " success: True\n",
            "       x: array([2.32952139, 3.17849113])\n",
            "[2.32952139 3.17849113]\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "x0 = np.array([1, 1])\n",
        "res = minimize(f, x0, method='COBYLA', constraints= [nonlinear_constraint])\n",
        "print(res)\n",
        "print(res.x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.array([0, 0])\n",
        "res = minimize(f, x0, method='COBYLA', constraints= [nonlinear_constraint])\n",
        "print(res)\n",
        "print(res.x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHns2jqxqxVj",
        "outputId": "55c1f2bb-02bb-4426-b9cb-0cf4343c8f86"
      },
      "id": "ZHns2jqxqxVj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     fun: -4.053708258184975\n",
            "   maxcv: 3.7853620753480755e-06\n",
            " message: 'Optimization terminated successfully.'\n",
            "    nfev: 19\n",
            "  status: 1\n",
            " success: True\n",
            "       x: array([0.61160344, 3.44210482])\n",
            "[0.61160344 3.44210482]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.array([1, 0])\n",
        "res = minimize(f, x0, method='COBYLA', constraints= [nonlinear_constraint])\n",
        "print(res)\n",
        "print(res.x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq1ktMuOvydX",
        "outputId": "9133f8c8-d703-4d02-ffcf-7a2ecd5250e1"
      },
      "id": "tq1ktMuOvydX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     fun: -5.508012518922257\n",
            "   maxcv: 3.6417964892621058e-06\n",
            " message: 'Optimization terminated successfully.'\n",
            "    nfev: 26\n",
            "  status: 1\n",
            " success: True\n",
            "       x: array([2.32952139, 3.17849113])\n",
            "[2.32952139 3.17849113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = np.array([0, 1])\n",
        "res = minimize(f, x0, method='COBYLA', constraints= [nonlinear_constraint])\n",
        "print(res)\n",
        "print(res.x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHZ3qsQov0gn",
        "outputId": "0dd58af9-c734-4ce6-e5fa-2fc274ed1b91"
      },
      "id": "rHZ3qsQov0gn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     fun: -4.053707750271545\n",
            "   maxcv: 5.169301875440624e-08\n",
            " message: 'Optimization terminated successfully.'\n",
            "    nfev: 21\n",
            "  status: 1\n",
            " success: True\n",
            "       x: array([0.61160323, 3.44210452])\n",
            "[0.61160323 3.44210452]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07591de",
      "metadata": {
        "id": "a07591de"
      },
      "source": [
        "## Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c1a08a",
      "metadata": {
        "id": "b0c1a08a"
      },
      "source": [
        "Type your report here. 中英文皆可"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method : trust-constr**\n",
        "\n",
        "is a trust-region algorithm for constrained optimization. It swiches between two implementations depending on the problem definition. It is the most versatile constrained minimization algorithm implemented in SciPy and the most appropriate for large-scale problems.\n",
        "\n",
        "reference link: https://www.google.com/search?q=Method+%3A+trust-constr&rlz=1C1RXQR_zh-TWTW1028TW1028&oq=Method+%3A+trust-constr&aqs=chrome..69i57.706j0j15&sourceid=chrome&ie=UTF-8\n",
        "\n",
        "# **Method : COBYLA**\n",
        "\n",
        "is an algorithm for minimizing a function of many variables. The method is derivatives free (only the function values are needed) and take into account constraints on the variables.\n",
        "\n",
        "It works by iteratively approximating the actual constrained optimization problem with linear programming problems. During an iteration, an approximating linear programming problem is solved to obtain a candidate for the optimal solution. The candidate solution is evaluated using the original objective and constraint functions, yielding a new data point in the optimization space. This information is used to improve the approximating linear programming problem used for the next iteration of the algorithm. When the solution cannot be improved anymore, the step size is reduced, refining the search. When the step size becomes sufficiently small, the algorithm finishes.\n",
        "\n",
        "reference link: https://zims-en.kiwix.campusafrica.gos.orange.com/wikipedia_en_all_nopic/A/COBYLA"
      ],
      "metadata": {
        "id": "gYxoPekvroKr"
      },
      "id": "gYxoPekvroKr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "根據上面跑的結果，可以看出如果使用 trust-constr method 的情況下，初始x0 = [0,0]  和 x0 = [0,1] 時，沒辦法成功的收斂完成，而 x0 = [1,1]和 x0 = [1,0] 時，才成功完成收斂。\n",
        "\n",
        "而使用 COBYLA method 的情況下，初始x0 = [0,0] or [1,1] or [1,0] or [0,1]時，都可以成功完成收斂。\n",
        "\n",
        "# **分析iteration:**\n",
        "\n",
        "COBYLA method 的情況下，從 nfev 顯示20幾次，看出可以使用很少的次數更新找到optimal point；trust-constr method的情況下差不多需要400多次才找到optimal point，並且初始 x0 也很重要，不一定都能收斂找到optimal point。\n",
        "\n",
        "# **分析fun**\n",
        "\n",
        "使用 COBYLA method 的情況下，找到的值都比使用 trust-constr method 的情況下小。\n",
        "\n"
      ],
      "metadata": {
        "id": "EJoOrAL8tWDJ"
      },
      "id": "EJoOrAL8tWDJ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}